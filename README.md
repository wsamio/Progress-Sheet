<div align="center">

# Daily Progress Log

<dev>

## February 18, 2023

| Activity | Time Spent | Things Learned | Problem Faced |
|:--------:|:----------:|----------------|---------------|


</div>



## February 17, 2023

| Activity | Time Spent | Things Learned | Problem Faced |
|:--------:|:----------:|----------------|---------------|
| Python Data-camp | 1.4 hrs | <ul><li>[Dictionaries](https://shorturl.at/kxMOP)</li></ul> | |
| Andrew Ng | 2.3 hrs | <ul><li>Supervised learning process</li><li>Model function</li><li>Univariate linear regression / Linear regression with one variable</li><li>[Straight line through the data lab](https://shorturl.at/zKNW6)</li></ul> | <ul><li> [ ] Linear regression model training and estimated target</li></ul> |

### Goals for Tomorrow
- Understanding Model representation lab, eventually disscuss it with Safaet
- Start linear algebra from Kahanacademy
- Start Panda package tutorial


<br><br><br>

## February 16, 2023

|    Activity    | Time Spent | Things Learned        | Problem Faced                                                                                |
|:--------------:|:----------:|-----------------------|----------------------------------------------------------------------------------------------|
| Progress Sheet |    2 hrs   | <ul><li>[Track Sheet](https://shorturl.at/ovDGI)</li><li>Functions</li><ul> | <ul><li>[x] ~~Add to do list~~</li> <li>[x] ~~How to add same formula to the whole column~~</li></ul>                      |
| Git            | 2.1 hrs    | <ul><li>Reminiscing Git</li></ul>       | <ul><li>[x] ~~How to work in an existing git repository~~</li> <li>[ ] What happens if I change the location of a folder.</li></ul> |
| Andrew Ng | 1 hrs | <ul> <li>Linear regression</li><li>Clustering Algorithm</li><li>Anomaly Detection</li><li>Dimentionality Detection</li><li>Notations</li></ul> | |

### Goals for Tomorrow
- Waste less time on the phone
- Recapture the git a little more
- Implement linear regression in Jupyter Notebook

<br><br>

## Overall Learned

### Programming
- skdfjl
    - askdjh
- skdh

### Algotithm

- [Gradient Descent](https://www.youtube.com/watch?v=sDv4f4s2SB8)
-
